{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vos8ORFrA-0P"
      },
      "outputs": [],
      "source": [
        "! pip install -Uq tensorboard sentence-transformers datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.init(mode=\"disabled\")"
      ],
      "metadata": {
        "id": "Tv6KE-G6V6LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets.utils.logging import disable_progress_bar\n",
        "disable_progress_bar()"
      ],
      "metadata": {
        "id": "1TA-JnrncdtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Create and Prepare embedding dataset**"
      ],
      "metadata": {
        "id": "_jlYwO8mBWI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"rasyosef/amharic-news-retrieval-dataset\", split=\"train\")\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAZEttOuBNx4",
        "outputId": "ab3d4b3b-025f-479e-c320-a0bdbe227ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:86: UserWarning: \n",
            "Access to the secret `HF_TOKEN` has not been granted on this notebook.\n",
            "You will not be requested again.\n",
            "Please restart the session if you want to be prompted again.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['query_id', 'passage_id', 'query', 'passage', 'category', 'link'],\n",
              "    num_rows: 44708\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rename columns\n",
        "dataset = dataset.rename_column(\"query\", \"anchor\")\n",
        "dataset = dataset.rename_column(\"passage\", \"positive\")"
      ],
      "metadata": {
        "id": "IO6ZPH-1rh_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an id column to the dataset\n",
        "dataset = dataset.add_column(\"id\", range(len(dataset)))\n",
        "dataset"
      ],
      "metadata": {
        "id": "Tl2lNJ--syE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2554fe71-de85-43da-8b7f-513d59b641d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['query_id', 'passage_id', 'anchor', 'positive', 'category', 'link', 'id'],\n",
              "    num_rows: 44708\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into a 10% test set\n",
        "dataset = dataset.class_encode_column(\"category\")\n",
        "dataset = dataset.train_test_split(test_size=0.1, seed=16, stratify_by_column=\"category\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "Z5K8B2NStVc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f634ef6f-bd86-4005-da13-b109f337e0ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['query_id', 'passage_id', 'anchor', 'positive', 'category', 'link', 'id'],\n",
              "        num_rows: 40237\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['query_id', 'passage_id', 'anchor', 'positive', 'category', 'link', 'id'],\n",
              "        num_rows: 4471\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Create baseline and evaluate pretrained model**"
      ],
      "metadata": {
        "id": "4GoNKHRrDN3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "train_dataset = dataset[\"train\"]\n",
        "test_dataset = dataset[\"test\"]\n",
        "corpus_dataset = concatenate_datasets([train_dataset, test_dataset])\n",
        "\n",
        "corpus_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqOtozrgDKvH",
        "outputId": "32180a93-bbea-45a5-c365-739d497bd564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['query_id', 'passage_id', 'anchor', 'positive', 'category', 'link', 'id'],\n",
              "    num_rows: 44708\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the datasets to dictionaries\n",
        "corpus = dict(\n",
        "    zip(corpus_dataset[\"id\"], corpus_dataset[\"positive\"])\n",
        ") # Our corpus (cid => document)\n",
        "queries = dict(\n",
        "    zip(test_dataset[\"id\"], test_dataset[\"anchor\"])\n",
        ") # Our queries (qid => question)"
      ],
      "metadata": {
        "id": "3pdE7K4jHSky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping of relevant document (1 in our case) for each query\n",
        "relevant_docs = {}\n",
        "for q_id in queries:\n",
        "  relevant_docs[q_id] = [q_id]"
      ],
      "metadata": {
        "id": "Pfj09jsPIsns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Evaluate Amharic Embedding model**\n",
        "\n",
        "List of models to evaluate:\n",
        "- intfloat/multilingual-e5-large-instruct\n",
        "- Alibaba-NLP/gte-modernbert-base\n",
        "- Alibaba-NLP/gte-multilingual-base\n"
      ],
      "metadata": {
        "id": "ei9-g0UmjLkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# model_id = \"rasyosef/roberta-amharic-text-embedding-base\"\n",
        "# model_id = \"rasyosef/roberta-amharic-text-embedding-medium\"\n",
        "# model_id = \"rasyosef/bert-amharic-text-embedding-medium\"\n",
        "\n",
        "# # OTHER MODELS\n",
        "# model_id = \"intfloat/multilingual-e5-large-instruct\"\n",
        "# model_id = \"Alibaba-NLP/gte-modernbert-base\"\n",
        "# model_id = \"Alibaba-NLP/gte-multilingual-base\"\n",
        "# model_id = \"Snowflake/snowflake-arctic-embed-l-v2.0\"\n",
        "model_id = \"rasyosef/snowflake-arctic-embed-l-v2.0-finetuned-amharic\"\n",
        "\n",
        "# Load a model\n",
        "model = SentenceTransformer(\n",
        "    model_id,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "print(model.max_seq_length)\n",
        "if model.max_seq_length > 1024:\n",
        "  model.max_seq_length = 1024\n",
        "model.max_seq_length"
      ],
      "metadata": {
        "id": "SuqcMD9nigo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers.evaluation import InformationRetrievalEvaluator, SequentialEvaluator\n",
        "from sentence_transformers.util import cos_sim\n",
        "\n",
        "EMBED_DIM = model.get_sentence_embedding_dimension()\n",
        "matryoshka_dimensions = [EMBED_DIM]\n",
        "\n",
        "print(\"Embedding Dimension:\", EMBED_DIM)\n",
        "\n",
        "matryoshka_evaluators = []\n",
        "# Iterate over the different dimensions\n",
        "for dim in matryoshka_dimensions:\n",
        "  ir_evaluator = InformationRetrievalEvaluator(\n",
        "      queries=queries,\n",
        "      corpus=corpus,\n",
        "      relevant_docs=relevant_docs,\n",
        "      batch_size=256,\n",
        "      name=f\"dim_{dim}\",\n",
        "      truncate_dim=dim,\n",
        "      score_functions={\"cosine\": cos_sim},\n",
        "      mrr_at_k=[10, 100],\n",
        "      ndcg_at_k=[10, 100],\n",
        "      precision_recall_at_k=[5, 10, 50, 100],\n",
        "      corpus_chunk_size=8192,\n",
        "      show_progress_bar=True\n",
        "  )\n",
        "  matryoshka_evaluators.append(ir_evaluator)\n",
        "\n",
        "# Create a sequential evaluator\n",
        "evaluator = SequentialEvaluator(matryoshka_evaluators)"
      ],
      "metadata": {
        "id": "qCZdGcu1J6NQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f15c4f0-1d4b-46e5-c1dc-fccd42a61745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Dimension: 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "results = evaluator(model)"
      ],
      "metadata": {
        "id": "ZGP_SjF750bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rasyosef/snowflake-arctic-embed-l-v2.0-finetuned-amharic\n",
        "\n",
        "dim = EMBED_DIM\n",
        "metrics = [\n",
        "    f\"dim_{dim}_cosine_recall@10\",\n",
        "    f\"dim_{dim}_cosine_recall@50\",\n",
        "    f\"dim_{dim}_cosine_recall@100\",\n",
        "    f\"dim_{dim}_cosine_mrr@10\",\n",
        "    f\"dim_{dim}_cosine_mrr@100\",\n",
        "    f\"dim_{dim}_cosine_ndcg@10\",\n",
        "    f\"dim_{dim}_cosine_ndcg@100\"\n",
        "  ]\n",
        "\n",
        "for key in metrics:\n",
        "  metric_name = key.split(\"_\")[-1]\n",
        "  print(f\"{metric_name}: {round(results[key], 3)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEF7LpCwMxnn",
        "outputId": "3ed1db71-d52e-42f5-d9bb-cfd48b670bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall@10: 0.942\n",
            "recall@50: 0.977\n",
            "recall@100: 0.985\n",
            "mrr@10: 0.827\n",
            "mrr@100: 0.829\n",
            "ndcg@10: 0.855\n",
            "ndcg@100: 0.865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Results**"
      ],
      "metadata": {
        "id": "oFwOX-vgeqVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **rasyosef/roberta-amharic-text-embedding-base**\n",
        "- recall@10: 0.913\n",
        "- recall@50: 0.964\n",
        "- recall@100: 0.979\n",
        "- mrr@10: 0.775\n",
        "- mrr@100: 0.778\n",
        "- ndcg@10: 0.808\n",
        "- ndcg@100: 0.823"
      ],
      "metadata": {
        "id": "bHwXhi3defU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **rasyosef/roberta-amharic-text-embedding-medium**\n",
        "- recall@10: 0.884\n",
        "- recall@50: 0.955\n",
        "- recall@100: 0.971\n",
        "- mrr@10: 0.735\n",
        "- mrr@100: 0.739\n",
        "- ndcg@10: 0.771\n",
        "- ndcg@100: 0.79"
      ],
      "metadata": {
        "id": "mac1gvQ_g_N9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **rasyosef/bert-amharic-text-embedding-medium**\n",
        "- recall@10: 0.843\n",
        "- recall@50: 0.931\n",
        "- recall@100: 0.954\n",
        "- mrr@10: 0.682\n",
        "- mrr@100: 0.686\n",
        "- ndcg@10: 0.72\n",
        "- ndcg@100: 0.744"
      ],
      "metadata": {
        "id": "KqESLADvhhai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **intfloat/multilingual-e5-large-instruct**\n",
        "- recall@10: 0.825\n",
        "- recall@50: 0.911\n",
        "- recall@100: 0.931\n",
        "- mrr@10: 0.672\n",
        "- mrr@100: 0.676\n",
        "- ndcg@10: 0.709\n",
        "- ndcg@100: 0.732"
      ],
      "metadata": {
        "id": "k5fc4yAnja1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Alibaba-NLP/gte-modernbert-base**\n",
        "- recall@10: 0.033\n",
        "- recall@50: 0.051\n",
        "- recall@100: 0.067\n",
        "- mrr@10: 0.019\n",
        "- mrr@100: 0.021\n",
        "- ndcg@10: 0.023\n",
        "- ndcg@100: 0.029\n"
      ],
      "metadata": {
        "id": "eN_VzLb9mXOd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Alibaba-NLP/gte-multilingual-base**\n",
        "- recall@10: 0.76\n",
        "- recall@50: 0.851\n",
        "- recall@100: 0.882\n",
        "- mrr@10: 0.6\n",
        "- mrr@100: 0.605\n",
        "- ndcg@10: 0.638\n",
        "- ndcg@100: 0.664"
      ],
      "metadata": {
        "id": "JP4fjxKTqe7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Snowflake/snowflake-arctic-embed-l-v2.0**\n",
        "- recall@10: 0.831\n",
        "- recall@50: 0.922\n",
        "- recall@100: 0.942\n",
        "- mrr@10: 0.659\n",
        "- mrr@100: 0.664\n",
        "- ndcg@10: 0.701\n",
        "- ndcg@100: 0.725"
      ],
      "metadata": {
        "id": "W0FigQrOqvhf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **rasyosef/snowflake-arctic-embed-l-v2.0-finetuned-amharic**\n",
        "\n",
        "- recall@10: 0.942\n",
        "- recall@50: 0.977\n",
        "- recall@100: 0.985\n",
        "- mrr@10: 0.827\n",
        "- mrr@100: 0.829\n",
        "- ndcg@10: 0.855\n",
        "- ndcg@100: 0.865"
      ],
      "metadata": {
        "id": "v-V2iXY8q9J_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Example**"
      ],
      "metadata": {
        "id": "mksHgOQTz_ZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "  \"የተደጋገመው የመሬት መንቀጥቀጥና የእሳተ ገሞራ ምልክት በአፋር ክልል\",\n",
        "  \"የዋጋ ግሽበት በባለሙያዎች እና ነዋሪዎች አተያይ\",\n",
        "  \"ከተደጋጋሚ መሬት መንቀጥቀጥ በኋላ አፋር ክልል እሳት ከመሬት ውስጥ ሲፈላ ታይቷል፡፡ ከመሬት ውስጥ እሳትና ጭስ የሚተፋው እንፋሎቱ ዛሬ ማለዳውን 11 ሰዓት ግድም ከከባድ ፍንዳታ በኋላየተስተዋለ መሆኑን የአከባቢው ነዋሪዎች እና ባለስልጣናት ለዶቼ ቬለ ተናግረዋል፡፡ አለት የሚያፈናጥር እሳት ነው የተባለው እንፋሎቱ በክልሉ ጋቢረሱ (ዞን 03) ዱለቻ ወረዳ ሰጋንቶ ቀበሌ መከሰቱን የገለጹት የአከባቢው የአይን እማኞች ከዋናው ፍንዳታ በተጨማሪ በዙሪያው ተጨማሪ ፍንዳታዎች መታየት ቀጥሏል ባይ ናቸው፡፡\",\n",
        "  \"ለኢትዮጵያ ብሔራዊ ባንክ ዋጋን የማረጋጋት ቀዳሚ ዓላማ ጋር የተጣጣሙ የገንዘብ ፖሊሲ ምክረ ሀሳቦችን እንዲሰጥ የተቋቋመው የኢትዮጵያ ብሔራዊ ባንክ የገንዘብ ፖሊሲ ኮሚቴ እስካለፈው ህዳር ወር የነበረው እአአ የ2024 የዋጋ ግሽበት በተለይምምግብ ነክ ምርቶች ላይ ከአንድ ዓመት በፊት ከነበው ጋር ሲነጻጸር መረጋጋት ማሳየቱን ጠቁሟል፡፡ ዶይቼ ቬለ ያነጋገራቸው የአዲስ አበባ ነዋሪዎች ግን በዚህ የሚስማሙ አይመስልም፡፡ ከአምና አንጻር ያልጨመረ ነገር የለም ባይ ናቸው፡፡ የኢኮኖሚ  ባለሙያም በሰጡን አስተያየት ጭማሪው በሁሉም ረገድ የተስተዋለ በመሆኑ የመንግስት ወጪን በመቀነስ ግብርናው ላይ አተኩሮ መስራት ምናልባትም የዋጋ መረጋጋቱን ሊያመጣ ይችላል ይላሉ፡፡\"\n",
        "]\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "# Get the similarity scores for the embeddings\n",
        "similarities = model.similarity(embeddings, embeddings)\n",
        "print(similarities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUnlkeUZmFfL",
        "outputId": "946a0019-12f2-463d-9bfe-44417baa1eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.1400, 0.6069, 0.0815],\n",
            "        [0.1400, 1.0000, 0.0104, 0.6810],\n",
            "        [0.6069, 0.0104, 1.0000, 0.0133],\n",
            "        [0.0815, 0.6810, 0.0133, 1.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QyjAhXbLqDOx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}