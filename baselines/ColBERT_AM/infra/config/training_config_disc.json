{
                "lr": 3e-5,
                "_description_lr": "Learning rate for the optimizer.",
              
                "bsize": 32,
                "_description_bsize": "Batch size (number of samples per training step).",
              
                "accumsteps": 1,
                "_description_accumsteps": "Accumulation steps for gradient accumulation.",
              
                "maxsteps": 10000,
                "_description_maxsteps": "Maximum number of training steps.",
              
                "query_maxlen": 32,
                "_description_query_maxlen": "Maximum query length (in tokens).",
              
                "doc_maxlen": 180,
                "_description_doc_maxlen": "Maximum document length (in tokens).",
              
                "checkpoint": "./bert-medium-amharic",
                "_description_checkpoint": "Checkpoint to initialize the model.",
              
                "triples": "dataset/triplets/train_triplets.jsonl",
                "_description_triples": "Path to the triplets file for training.",
              
                "collection": "dataset/assessed_document_collection.jsonl",
                "_description_collection": "Path to the collection of documents.",
              
                "queries": "dataset/splits/train_topics.jsonl",
                "_description_queries": "Path to the query file.",
              
                "use_ib_negatives": false,
                "_description_use_ib_negatives": "This parameter controls the type of loss function used during training. When set to false, the training follows the pairwise ranking loss as described in the original ColBERT paper. In this mode, the model optimizes the separation between positive and negative documents for each query using only the provided triplet data (query, positive document, negative document). When set to true, in-batch negatives are enabled. In this mode, all other documents in the same training batch are treated as potential negatives for the current query, increasing the diversity of negatives and allowing for a more robust ranking model. Note that enabling this requires careful batch construction to avoid false negatives (e.g., treating relevant documents as negatives), and it may improve generalization for datasets with sparse or incomplete relevance annotations.",
                "loss_type": "pairwise",
                "__description_": "Type of loss function to use (pairwise for pairwise ranking loss)"

              
              }
              